<!doctype html>
<html lang="ru" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Machine-learning/Metric-methods/KNN-analysis" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">Анализ метода K ближайших соседей | Машинное и глубокое обучение</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://deepmachinelearning.ru/img/social-card2.png"><meta data-rh="true" name="twitter:image" content="https://deepmachinelearning.ru/img/social-card2.png"><meta data-rh="true" property="og:url" content="https://deepmachinelearning.ru/docs/Machine-learning/Metric-methods/KNN-analysis"><meta data-rh="true" property="og:locale" content="ru"><meta data-rh="true" name="docusaurus_locale" content="ru"><meta data-rh="true" name="docsearch:language" content="ru"><meta data-rh="true" name="keywords" content="машинное обучение, глубокое обучение, глубокое машинное обучение, анализ данных, machine learning, deep learning, data science обучение, искусственный интеллект, ИИ, машинное обучение книги, машинное обучение курсы, методы прогнозирования"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Анализ метода K ближайших соседей | Машинное и глубокое обучение"><meta data-rh="true" name="description" content="Преимущества и недостатки метода K ближайших соседей. Понятие проклятия размерности (curse of dimensionality)."><meta data-rh="true" property="og:description" content="Преимущества и недостатки метода K ближайших соседей. Понятие проклятия размерности (curse of dimensionality)."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://deepmachinelearning.ru/docs/Machine-learning/Metric-methods/KNN-analysis"><link data-rh="true" rel="alternate" href="https://deepmachinelearning.ru/docs/Machine-learning/Metric-methods/KNN-analysis" hreflang="ru"><link data-rh="true" rel="alternate" href="https://deepmachinelearning.ru/docs/Machine-learning/Metric-methods/KNN-analysis" hreflang="x-default"><link rel="preconnect" href="https://mc.yandex.ru">
<script>!function(e,t,a,c,n,r,i){e[n]=e[n]||function(){(e[n].a=e[n].a||[]).push(arguments)},e[n].l=1*new Date,r=t.createElement(a),i=t.getElementsByTagName(a)[0],r.async=1,r.src="https://mc.yandex.ru/metrika/tag.js",i.parentNode.insertBefore(r,i)}(window,document,"script",0,"ym"),ym(98444042,"init",{defer:!0,clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!1,ecommerce:!1,trackHash:!1})</script>
<noscript>
                            <div><img src="https://mc.yandex.ru/watch/98444042" style="position:absolute; left:-9999px;" alt=""></div>
                        </noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.8f598318.css">
<script src="/assets/js/runtime~main.f5fe1c03.js" defer="defer"></script>
<script src="/assets/js/main.0773afd7.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Перейти к основному содержимому"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Перейти к основному содержимому</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Переключить навигационную панель" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Machine-learning/book-title">Машинное обучение</a><a class="navbar__item navbar__link" href="/docs/Neural-networks/book-title">Глубокое обучение</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/abbreviations">Обозначения</a><a class="navbar__item navbar__link" href="/license">Лицензия</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Переключение между темным и светлым режимом (сейчас используется Светлый режим)" aria-label="Переключение между темным и светлым режимом (сейчас используется Светлый режим)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Прокрутка к началу" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Machine-learning/book-title">Машинное обучение</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Machine-learning/intro">Введение</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Base-concepts">Основы машинного обучения</a><button aria-label="Expand sidebar category &#x27;Основы машинного обучения&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Data-preprocessing">Подготовка данных</a><button aria-label="Expand sidebar category &#x27;Подготовка данных&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/General-classifiers">Классификаторы в общем виде</a><button aria-label="Expand sidebar category &#x27;Классификаторы в общем виде&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/Machine-learning/Metric-methods">Метрические методы прогнозирования</a><button aria-label="Collapse sidebar category &#x27;Метрические методы прогнозирования&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Metric-methods">Метрические методы</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Nearest-centroids">Метод ближайших центроидов</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/KNN">Метод K ближайших соседей</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Machine-learning/Metric-methods/KNN-analysis">Анализ метода K ближайших соседей</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Weighted-KNN">Обобщение метода K ближайших соседей с весами</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Weights-selection">Веса в метрических методах</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Local-constant-regression">Локально-постоянная регрессия</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Distance-functions">Функции расстояния</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Local-linear-regression">Локально-линейная регрессия</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Machine-learning/Metric-methods/Questions">Вопросы</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Linear-regression-extensions">Линейная регрессия и её обобщения</a><button aria-label="Expand sidebar category &#x27;Линейная регрессия и её обобщения&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Regression-evaluation">Оценка качества регрессии</a><button aria-label="Expand sidebar category &#x27;Оценка качества регрессии&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Linear-classification">Линейная классификация</a><button aria-label="Expand sidebar category &#x27;Линейная классификация&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Multiclass-with-binary-classifiers">Многоклассовая классификация набором бинарных классификаторов</a><button aria-label="Expand sidebar category &#x27;Многоклассовая классификация набором бинарных классификаторов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Numerical-optimization">Численная оптимизация</a><button aria-label="Expand sidebar category &#x27;Численная оптимизация&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Classifier-evaluation">Оценка качества классификации</a><button aria-label="Expand sidebar category &#x27;Оценка качества классификации&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Decision-trees">Решающие деревья</a><button aria-label="Expand sidebar category &#x27;Решающие деревья&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Overfitting-and-underfitting">Переобучение и недообучение</a><button aria-label="Expand sidebar category &#x27;Переобучение и недообучение&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Model-ensembles">Ансамбли моделей</a><button aria-label="Expand sidebar category &#x27;Ансамбли моделей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Boosting">Бустинг</a><button aria-label="Expand sidebar category &#x27;Бустинг&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Simple-models-interpretation">Интерпретация простых моделей</a><button aria-label="Expand sidebar category &#x27;Интерпретация простых моделей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Machine-learning/Complex-models-interpretation">Интерпретация сложных моделей</a><button aria-label="Expand sidebar category &#x27;Интерпретация сложных моделей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Machine-learning/whats-next">Заключение</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Навигационная цепочка текущей страницы"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Главная страница" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/Machine-learning/Metric-methods"><span itemprop="name">Метрические методы прогнозирования</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Анализ метода K ближайших соседей</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">Содержание этой страницы</button></div><div class="theme-doc-markdown markdown"><h1>Анализ метода K ближайших соседей</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="достоинства-метода">Достоинства метода<a class="hash-link" aria-label="Прямая ссылка на Достоинства метода" title="Прямая ссылка на Достоинства метода" href="/docs/Machine-learning/Metric-methods/KNN-analysis#достоинства-метода">​</a></h2>
<p>Метод K ближайших соседей легко реализовать, и он является интерпретируемым методом: всегда можно обосновать его прогноз, сославшись на похожие объекты в обучающей выборке, отклик для которых известен. Свойство интерпретируемости важно в приложениях, в которых цена ошибочного прогноза велика, например, в медицине, где ценой ошибки может быть жизнь пациента.</p>
<p>Метод не требует обучения - нужно лишь сохранить обучающие объекты в памяти, поэтому качество его работы можно оценивать <a href="/docs/Machine-learning/Base-concepts/Quality-estimation#%D0%BA%D1%80%D0%BE%D1%81%D1%81-%D0%B2%D0%B0%D0%BB%D0%B8%D0%B4%D0%B0%D1%86%D0%B8%D1%8F">кросс-валидацией</a> с большим числом блоков и даже скользящим контролем (когда число блоков совпадает с числом объектов выборки).</p>
<p>Метод может применяться в <strong>онлайн-обучении</strong> (online machine learning), когда данные поступают динамическим потоком и быстро устаревают, например, при автоматической торговле на бирже. Для этого в качестве обучающей выборке нужно учитывать только те объекты, которые мы недавно пронаблюдали.</p>
<p>Метод легко подхватывает основные паттерны в данных, запоминая примеры каждого случая. Поэтому метод легко может оказаться лучшим, например, в классификации на очень большое число классов, когда число представителей каждого класса мало.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="недостатки-метода">Недостатки метода<a class="hash-link" aria-label="Прямая ссылка на Недостатки метода" title="Прямая ссылка на Недостатки метода" href="/docs/Machine-learning/Metric-methods/KNN-analysis#недостатки-метода">​</a></h2>
<p>Для работы метода необходимо хранить все объекты обучающей выборки, поскольку все объекты по сути и составляют параметры метода.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Параметрические и непараметрические методы</div><div class="admonitionContent_BuS1"><p>Методы, в которых число параметров растёт с ростом объема выборки называются <strong>непараметрическими</strong> в противоположность <strong>параметрическим</strong>  методам, в которых число параметров заранее фиксировано. Например распределение случайной величины мы можем моделировать Гауссовым распределением - тогда, с ростом выборки наблюдений, число параметров (среднее и матрица ковариации) будет оставаться прежним. Если же мы оцениваем распределение гистограммой, то, с ростом числа наблюдений, логично делать гистограмму более точной, увеличивая число столбцов гистограммы с ростом числа наблюдений. И этот метод становится уже непараметрическим.</p><p>Непараметрические методы не делают таких существенных предположений о распределении данных, как параметрические, поэтому обычно работают точнее, когда накоплено достаточное количество наблюдений.</p></div></div>
<p>При построении прогноза даже для одного объекта требуется вычисление расстояний от этого объекта <em>до всех объектов обучающей выборки</em>, чтобы найти K ближайших соседей. Поэтому в простейшей реализации метод применим лишь для малых выборок или в ситуациях, когда скорость построения прогнозов не важна.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Ускорение поиска ближайших соседей</div><div class="admonitionContent_BuS1"><p>Существуют подходы ускорения прогнозов метода K ближайших соседей, усложняющие его обучение и снижающие его применимость в онлайн-обучении.</p><ul>
<li>
<p>Можно ускорить вычисление расстояний между объектами, снизив число признаков.</p>
</li>
<li>
<p>Можно уменьшить размер выборки, отобрав только эталонные объекты для каждого класса и существенные объекты на границах между классами, отбросив неинформативные.</p>
</li>
<li>
<p>Можно упорядочить объекты по определённой структуре признакового пространства. Поиск похожих объектов вместо полного перебора тогда сведётся к направленному поиску по этой структуре (KD-trees, ball-trees либо направленный поиск по <strong>графу близости между объ ектами</strong> (proximity graph)).</p>
</li>
<li>
<p>Можно использовать <strong>локально-чувствительное хэширование</strong> (locality sensitive hashing), при котором строится хэш-функция, отображающая метрически близкие объекты в одинаковые значения. Тогда, отобразив целевой объект в какое-то значение хэш-функции, можно сразу найти похожие объекты. Это будут объекты обучающей выборки, для которых хэш-функция приняла такое же значение.</p>
</li>
</ul></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="проклятие-размерности">Проклятие размерности<a class="hash-link" aria-label="Прямая ссылка на Проклятие размерности" title="Прямая ссылка на Проклятие размерности" href="/docs/Machine-learning/Metric-methods/KNN-analysis#проклятие-размерности">​</a></h3>
<p>Также метод подвержен так называемому <strong>проклятию размерности</strong> (curse of dimensionality). Суть проклятия размерности заключается в том, что с ростом размерности признакового пространства <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span> для обеспечения определённого уровня точности ме тоду необходим экспоненциальный рост числа наблюдений (относительно <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>). Если же рост числа наблюдений не происходит, то точность работы метода снижается. Пусть нам нужно построить прогноз для объекта <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">\mathbf{x}\in\mathbb{R}^D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathbf">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span></span>. Поместим этот объект в центр двух вложенных друг в друга  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>-мерных кубов со сторонами <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span> и <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>−</mo><mi>ε</mi></mrow><annotation encoding="application/x-tex">S-\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span></span></span></span>, где <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">ε</span></span></span></span> - какая-то малая фиксированная константа, например 0.001. Тогда объем внутреннего куба будет <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>S</mi><mo>−</mo><mi>ε</mi><msup><mo stretchy="false">)</mo><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">(S-\varepsilon)^D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mord mathnormal">ε</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span></span>, а объём внешнего - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mi>D</mi></msup></mrow><annotation encoding="application/x-tex">S^D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span></span>. Отношение двух объёмов будет экспоненциально быстро стремиться к нулю с ростом <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>, и уже при  небольшом значении <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span> будет пренебрежимо малым:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mo stretchy="false">(</mo><mi>S</mi><mo>−</mo><mi>ε</mi><msup><mo stretchy="false">)</mo><mi>D</mi></msup></mrow><msup><mi>S</mi><mi>D</mi></msup></mfrac><mo>=</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi>S</mi><mo>−</mo><mi>ε</mi></mrow><mi>S</mi></mfrac><mo fence="true">)</mo></mrow><mi>D</mi></msup><mo>→</mo><mn>0</mn><mtext> при </mtext><mi>D</mi><mo>→</mo><mi mathvariant="normal">∞</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\frac{(S-\varepsilon)^D}{S^D}=\left(\frac{S-\varepsilon}{S}\right)^D \to 0 \text{ при } D\to\infty.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.2043em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7673em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">ε</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.6313em;vertical-align:-0.95em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">ε</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.6812em"><span style="top:-3.9029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em">D</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord">0</span><span class="mord text"><span class="mord"> </span><span class="mord cyrillic_fallback">при</span><span class="mord"> </span></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord">∞.</span></span></span></span></span>
<p>Это означает, что доля объема, покрываемого внутренним кубом от объема внешнего куба будет становиться пренебрежимо малой, а почти весь объем внешнего куба будет концентрироваться на его границе. Аналогичные рассуждения можно провести и для двух сфер вокруг целевого объекта - с ростом <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span> почти весь объем внешней сферы будет концентрироваться на её границе.</p>
<p>При равномерном распределении объектов в признаковом пространстве вероятность пронаблюдать объект в определённой области будет пропорциональна объёму области. Значит, при поиске ближайших объектов к заданному эти объекты, скорее всего, будут располагаться не рядом, а на удалении от него. Ближайшие соседи перестанут оказываться метрически близкими и перестанут репрезентативно описывать отклик целевого объекта.</p>
<p>Это можно понять и проще - чем больше случайных признаков описывает отклик объекта, тем в среднем более удалёнными объекты будут оказываться друг от друга при вычислении расстояний между ними. Таким образом, ближайшие соседи перестают быть на самом деле близкими, и предсказательная сила их откликов для целевого объекта снижается.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Не всё так плохо</div><div class="admonitionContent_BuS1"><p>Проклятие размерности - скорее теоретическая проблема. На практике, несмотря на то, что мы можем рассматривать все больше и больше признаков, они скорее всего будут скоррелированы друг с другом. Поэтому даже при увеличении размерности признакового пространства объекты будут заполнять его не равномерно, а на некотором многообразии меньшей размерности, вследствие чего метод будет работать лучше ожиданий. Однако об этой особенности следует помнить, чтобы не добавлять лишних признаков, слабо влияющих на отклик, иначе они могут снизить качество прогнозов.</p></div></div></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Страница документа"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Machine-learning/Metric-methods/KNN"><div class="pagination-nav__sublabel">Предыдущая страница</div><div class="pagination-nav__label">Метод K ближайших соседей</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Machine-learning/Metric-methods/Weighted-KNN"><div class="pagination-nav__sublabel">Следующая страница</div><div class="pagination-nav__label">Обобщение метода K ближайших соседей с весами</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/Machine-learning/Metric-methods/KNN-analysis#достоинства-метода">Достоинства метода</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Machine-learning/Metric-methods/KNN-analysis#недостатки-метода">Недостатки метода</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/Machine-learning/Metric-methods/KNN-analysis#проклятие-размерности">Проклятие размерности</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2023-25 <a href="https://victorkitov.github.io/">Виктор Китов</a>.</div></div></div></footer></div>
</body>
</html>