<!doctype html>
<html lang="ru" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Neural-networks/Object-detection/Two-stage-detectors" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">Двухстадийные детекторы | Машинное и глубокое обучение</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://deepmachinelearning.ru/img/social-card2.png"><meta data-rh="true" name="twitter:image" content="https://deepmachinelearning.ru/img/social-card2.png"><meta data-rh="true" property="og:url" content="https://deepmachinelearning.ru/docs/Neural-networks/Object-detection/Two-stage-detectors"><meta data-rh="true" property="og:locale" content="ru"><meta data-rh="true" name="docusaurus_locale" content="ru"><meta data-rh="true" name="docsearch:language" content="ru"><meta data-rh="true" name="keywords" content="машинное обучение, глубокое машинное обучение, анализ данных, machine learning, deep learning, data science обучение, искусственный интеллект, машинное обучение книги, машинное обучение курсы, методы прогнозирования"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Двухстадийные детекторы | Машинное и глубокое обучение"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://deepmachinelearning.ru/docs/Neural-networks/Object-detection/Two-stage-detectors"><link data-rh="true" rel="alternate" href="https://deepmachinelearning.ru/docs/Neural-networks/Object-detection/Two-stage-detectors" hreflang="ru"><link data-rh="true" rel="alternate" href="https://deepmachinelearning.ru/docs/Neural-networks/Object-detection/Two-stage-detectors" hreflang="x-default"><link rel="preconnect" href="https://mc.yandex.ru">
<script>!function(e,t,a,c,n,r,i){e[n]=e[n]||function(){(e[n].a=e[n].a||[]).push(arguments)},e[n].l=1*new Date,r=t.createElement(a),i=t.getElementsByTagName(a)[0],r.async=1,r.src="https://mc.yandex.ru/metrika/tag.js",i.parentNode.insertBefore(r,i)}(window,document,"script",0,"ym"),ym(98444042,"init",{defer:!0,clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!1,ecommerce:!1,trackHash:!1})</script>
<noscript>
                            <div><img src="https://mc.yandex.ru/watch/98444042" style="position:absolute; left:-9999px;" alt=""></div>
                        </noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.1c01f2a4.css">
<script src="/assets/js/runtime~main.65a035bc.js" defer="defer"></script>
<script src="/assets/js/main.4ebd01e5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Перейти к основному содержимому"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Перейти к основному содержимому</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Переключить навигационную панель" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/docs/Machine-learning/book-title">Машинное обучение</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Neural-networks/book-title">Глубокое обучение</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/abbreviations">Обозначения</a><a class="navbar__item navbar__link" href="/license">Лицензия</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Переключение между темным и светлым режимом (сейчас используется Светлый режим)" aria-label="Переключение между темным и светлым режимом (сейчас используется Светлый режим)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Прокрутка к началу" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Neural-networks/book-title">Глубокое обучение</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Neural-networks/intro">Введение</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Tasks-of-deep-learning">Примеры задач глубокого обучения</a><button aria-label="Expand sidebar category &#x27;Примеры задач глубокого обучения&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Multilayer-perceptron">Основы нейросетевых архитектур</a><button aria-label="Expand sidebar category &#x27;Основы нейросетевых архитектур&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Training-neural-networks">Обучение нейросетей</a><button aria-label="Expand sidebar category &#x27;Обучение нейросетей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Training-simplification">Упрощение настройки</a><button aria-label="Expand sidebar category &#x27;Упрощение настройки&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Regularization">Регуляризация при настройке нейросетей</a><button aria-label="Expand sidebar category &#x27;Регуляризация при настройке нейросетей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Special-architectures">Специальные архитектуры</a><button aria-label="Expand sidebar category &#x27;Специальные архитектуры&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Convolution-for-sequences-1D">Локальная обработка последовательностей</a><button aria-label="Expand sidebar category &#x27;Локальная обработка последовательностей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Convolution-for-images-2D">Локальная обработка изображений</a><button aria-label="Expand sidebar category &#x27;Локальная обработка изображений&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Convolutional-architectures">Основные свёрточные архитектуры</a><button aria-label="Expand sidebar category &#x27;Основные свёрточные архитектуры&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Semantic-segmentation">Семантическая сегментация</a><button aria-label="Expand sidebar category &#x27;Семантическая сегментация&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/Neural-networks/Object-detection">Детекция объектов</a><button aria-label="Collapse sidebar category &#x27;Детекция объектов&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/Object-detection-task">Детекция объектов</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/Quality-metrics">Оценка качества детекции</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/Non-maximum-supression">Подавление не-максимумов</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/YOLO">YOLO</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/SSD">SSD</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/Feature-Proposal-Network">Сеть пирамидальных признаков</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/RetinaNet">RetinaNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/CornerNet">CornerNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/CenterNet">CenterNet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Neural-networks/Object-detection/Two-stage-detectors">Двухстадийные детекторы</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/Object-detection/Deformable-CNN">Деформируемые архитектуры</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/сегментация-объектов">Сегментация объектов</a><button aria-label="Expand sidebar category &#x27;Сегментация объектов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/эмбеддинги-слов-и-параграфов">Эмбеддинги слов и параграфов</a><button aria-label="Expand sidebar category &#x27;Эмбеддинги слов и параграфов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/рекуррентные-сети">Рекуррентные сети</a><button aria-label="Expand sidebar category &#x27;Рекуррентные сети&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/механизм-внимания-и-трансформер">Механизм внимания и трансформер</a><button aria-label="Expand sidebar category &#x27;Механизм внимания и трансформер&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/category/обработка-графов">Обработка графов</a><button aria-label="Expand sidebar category &#x27;Обработка графов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Neural-networks/conclusion">Заключение</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Навигационная цепочка текущей страницы"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Главная страница" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/Neural-networks/Object-detection"><span itemprop="name">Детекция объектов</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Двухстадийные детекторы</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">Содержание этой страницы</button></div><div class="theme-doc-markdown markdown"><h1>Двухстадийные детекторы</h1>
<p>Ранее рассмотренные методы детекции  объектов являются одностадийными (one-stage detectors) - они на вход принимают изображение, а на выходе сразу выдают рамки с сопоставленными этим рамкам классами.</p>
<p>Двухстадийные детекторы (two-stage detectors) же решают задачу детекции в два шага:</p>
<ul>
<li>
<p>на первом шаге извлекают регионы-кандидаты (region proposals, regions of interest, ROI)</p>
</li>
<li>
<p>на втором шаге относят извлечённые регионы-кандидаты к тому или иному классу и уточняют их расположение.</p>
</li>
</ul>
<p>Из-за двух этапов генерации такие методы работают медленнее, чем одностадийные, но при тщательной настройке могут обеспечить более высокую точность.</p>
<p>Исторически первыми нейросетевыми детекторами были именно двухстадийные детекторы. Рассмотрим самый известный 2-х стадийный детектор Faster R-CNN.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="faster-r-cnn">Faster R-CNN<a class="hash-link" aria-label="Прямая ссылка на Faster R-CNN" title="Прямая ссылка на Faster R-CNN" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#faster-r-cnn">​</a></h2>
<p>Детекция объектов на изображении моделью Faster R-CNN [<a href="https://papers.nips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html" target="_blank" rel="noopener noreferrer">1</a>] состоит из следующих шагов:</p>
<ul>
<li>
<p>генерация регионов-кандидатов (region proposals) с помощью специальной RPN сети (region proposal network)</p>
</li>
<li>
<p>подавление не-максимумов для выделения минимально достаточного набора кандидатов, покрывающих объекты</p>
</li>
<li>
<p>отбор топ K самых высокорейтинговых регионов-кандидатов</p>
</li>
<li>
<p>классификация и уточнение выделяющей рамки для каждого объекта</p>
</li>
<li>
<p>итоговое подавление не-максимумов</p>
</li>
</ul>
<p>Последний этап повторяет модель Fast R-CNN, описанную далее.</p>
<p>Схема Faster R-CNN представлена ниже [<a href="https://www.researchgate.net/publication/324903264_Multi-scale_object_detection_in_remote_sensing_imagery_with_convolutional_neural_networks" target="_blank" rel="noopener noreferrer">2</a>]:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/Faster-R-CNN-architecture-17e2b4ed76882f45b03a5fac2b0e9146.jpg" width="1778" height="705" class="img_ev3q"></p>
<p>Вначале изображение обрабатывается первыми слоями свёрточной сети, предобученной решать задачу классификации, извлекающей признаковое описание изображения. Далее к нему применяется сеть, предсказывающая регионы интереса (region proposal network, RPN):</p>
<ol>
<li>
<p>К полученному признаковому описанию скользящим окном 3x3 применяются свёртки, выдающие 256 признаков.</p>
</li>
<li>
<p>К 256-мерному вектору в каждой позиции применяется полносвязная сеть, предсказывающая для каждой из k шаблонных рамок, центрированных в текущей позиции,</p>
<ol>
<li>
<p>2 классификационных выхода (вероятность присутствия и отсутствия объекта)</p>
</li>
<li>
<p>4 регрессионных выхода (изменение координат соответствующей шаблонной рамки по координатам центра, ширине и высоте)</p>
</li>
</ol>
</li>
</ol>
<p>Шаги 2 и 3 графически показаны ниже [<a href="https://papers.nips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html" target="_blank" rel="noopener noreferrer">1</a>]:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/region-proposal-network-7f4e8d0c5a8cf5d1f2fb61177f82a7ab.png" width="799" height="485" class="img_ev3q"></p>
<p>Технически шаг 2 - это один слой из 3x3 свёрток с 256 выходами, а шаг 3 - слой из свёрток 1x1. Таким образом, всю RPN сеть можно описать двумя обычными свёрточными слоями.</p>
<p>К полученным регионам кандидатам применяется подавление не-максимов и отбор топ-K самых высокорейтинговых регионов, после чего на извлечённых регионах уже работает сеть Fast R-CNN, производящая окончательную детекцию.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Точность работы</div><div class="admonitionContent_BuS1"><p>Модель Faster R-CNN была предложена в 2015 году и впоследствии обгонялась и по точности более быстрыми одностадийными детекторами. Однако точность Faster R-CNN можно повысить, используя более продвинутые сети для извлечения промежуточного представления, генерации регионов-кандидатов, классификатора и локализатора. Более продвинутые варианты этой модели продолжают составлять конкуренцию одностадийным детекторам.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="fast-r-cnn">Fast R-CNN<a class="hash-link" aria-label="Прямая ссылка на Fast R-CNN" title="Прямая ссылка на Fast R-CNN" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#fast-r-cnn">​</a></h2>
<p>Модель Fast R-CNN [<a href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html" target="_blank" rel="noopener noreferrer">3</a>] детектирует объекты по изображению, на которых уже выделены регионы-кандидаты. В оригинальной версии метода для этого используются регионы-кандидаты, выделяемые эвристическим методов selective search [<a href="http://www.huppelen.nl/publications/selectiveSearchDraft.pdf" target="_blank" rel="noopener noreferrer">4</a>].</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="алгоритм-selective-search">Алгоритм selective search<a class="hash-link" aria-label="Прямая ссылка на Алгоритм selective search" title="Прямая ссылка на Алгоритм selective search" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#алгоритм-selective-search">​</a></h3>
<p>Алгоритм selective search использует не нейросети, а алгоритм классического компьютерного зрения. Вначале он разбивает изображение на области, в качестве которых выступают суперпиксели (superpixels), т.е. небольшие области соседних пикселей, примерно похожих по цвету. На основе первоначальных областей алгоритм начинает их итеративное объединение жадным способом, т.е. объединяя в первую очередь соседние и самые похожие области. Объединение происходит по определенным критериям сходства:</p>
<ul>
<li>
<p>Текстура: схожесть гистограмм градиентов соседних областей.</p>
</li>
<li>
<p>Размер: относительная площадь двух областей (предпочтение отдается объединению небольших областей).</p>
</li>
<li>
<p>Заполнение: насколько одна область перекрывает другую.</p>
</li>
</ul>
<p>Процесс объединения областей продолжается, пока не останется всего одна область. Регионами-кандидатами выступают прямоугольники, обведённые вокруг каждой области, по лученной в процессе работы алгоритма.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Faster R-CNN и Fast-RCNN</div><div class="admonitionContent_BuS1"><p>Алгоритм Faster R-CNN отличается от Fast-RCNN только методом извлечения регионов-кандидатов. В Fast-RCNN используется selective search, а в Faster R-CNN - сеть генерации регионов-кандидатов. Первый метод итеративный и не поддаётся параллелизации, а сеть генерации регионов-кандидатов состоит из 2х свёрточных слоёв, которые можно быстро вычислить на видеокарте. Поэтому Faster R-CNN работает значительно быстрее, чем Fast R-CNN!</p><p>Как только регионы-кандидаты извлечены, работа двух методов не различается.</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="обработка-регионов-кандидатов-в-fast-rcnn">Обработка регионов-кандидатов в Fast-RCNN<a class="hash-link" aria-label="Прямая ссылка на Обработка регионов-кандидатов в Fast-RCNN" title="Прям ая ссылка на Обработка регионов-кандидатов в Fast-RCNN" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#обработка-регионов-кандидатов-в-fast-rcnn">​</a></h3>
<p>Схема работы Fast-RCNN показана на рисунке [<a href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html" target="_blank" rel="noopener noreferrer">3</a>]:</p>
<p><img decoding="async" loading="lazy" src="/assets/images/Fast-R-CNN-3c1dbe44b3724566eb59e06a43485818.jpg" width="1068" height="405" class="img_ev3q"></p>
<p>Изображение пропускается через свёрточный кодировщик (первые свёрточные слои сети, обученной решать задачу классификации), чтобы получить её промежуточное представление с <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span> каналами.</p>
<p>Извлечённые регионы-кандидаты перемасштабируются под размер промежуточного представления (пропорционально уменьшаются пространственные координаты).</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Faster R-CNN и Fast-RCNN</div><div class="admonitionContent_BuS1"><p>Модель Faster R-CNN извлекает регионы-кандидаты с того же самого внутреннего представления. За счёт этого его не нужно перевычислять дважды и Faster R-CNN работает быстрее.</p></div></div>
<p>Далее каждый регион-кандидат обрабатывается независимо. Осуществляется перевод внутреннего представления, выделенного регионом-кандидатом, в вектор фиксированного размера <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>P</mi><mn>2</mn></msup><mi>S</mi></mrow><annotation encoding="application/x-tex">P^2 S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span> за счёт пулинга региона интереса (region-of-interest pooling, ROI pooling). Этот пулинг накладывает на регион интереса сетку <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>P</mi></mrow><annotation encoding="application/x-tex">P\times P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span>, а далее возвращает максимальные элементы из всех активаций, покрытых каждой ячейкой сетки. Делается это независимо для каждого канала, потом результаты для всех каналов объединяются. По сути пулинг региона интереса производит пирамидальный пулинг, но только на одном слое пирамиды.</p>
<p>После кодирования указанным пулингом региона интереса вектором фиксированного размера, к этому вектору применяется два полносвязных слоя. Первый переводит в вход в вектор ещё более маленького размера, а второй, наоборот, расширяет - это позволяет сэкономить на числе связей. К результату применяется два независимых полносвязных слоя:</p>
<ul>
<li>
<p>первый выдаёт <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">C+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> вероятностей, соответствующих каждому из классов и фоновому классу (отсутствию объекта)</p>
</li>
<li>
<p>второй выдаёт <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span> выхода, трактуемые как уточнённые координаты <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x,y,w,h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mclose">)</span></span></span></span> первоначальной рамки региона-кандидата.</p>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="настройка-fast-r-cnn">Настройка Fast R-CNN<a class="hash-link" aria-label="Прямая ссылка на Настройка Fast R-CNN" title="Прямая ссылка на Настройка Fast R-CNN" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#настройка-fast-r-cnn">​</a></h3>
<p>Fast R-CNN, как и все нейросети, настраивается минибатчами. Каждый минибатч состоит из набора регионов интереса. Для ускоренной настройки используется иерархическое сэмплирование регионов:</p>
<ol>
<li>
<p>вначале сэмплируется набор изображений</p>
</li>
<li>
<p>затем для каждого изображения сэмплируется набор регионов интереса</p>
</li>
</ol>
<p>Такая иерархическая генерация минибатча работает быстрее, чем случайный выбор изображения и региона, поскольку многие регионы будут оказываться на одном изображении, а следовательно для них промежуточное представление можно вычислить всего один раз.</p>
<p>Сэмплирование регионов интереса производилось сбалансированным по целевым и фонов ому классу, для этого вычислялась мера IoU между истинными и предсказанными выделениями:</p>
<ul>
<li>
<p>половина регионов бралась с <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>o</mi><mi>U</mi><mo>≥</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">IoU\ge 0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span>, и от классификатора требовалось угадать верный класс;</p>
</li>
<li>
<p>другая половина бралась с <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>o</mi><mi>U</mi><mo>&lt;</mo><mn>0.5</mn></mrow><annotation encoding="application/x-tex">IoU&lt;0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.5</span></span></span></span> и от классификатора требовалось угадать, что класс является фоном.</p>
</li>
</ul>
<p>Настройка сети производится минимизацией суммы потерь классификации и  локализации.</p>
<ul>
<li>
<p>потери классификации измеряют, насколько корректно угадан класс объекта, а математически представляют собой обычные кросс-энтропийные потери;</p>
</li>
<li>
<p>потери локализации измеряют, насколько сочетается предсказанная рамка и рамка истинного выделения и вычисляются лишь для тех рамок, на которых классификатор обнаружил не фоновый класс, а рамка существенно пересекается с истинной рамкой объекта.</p>
</li>
</ul>
<p>В качестве потерь локализации берётся функция потерь Хубера (smooth L1 loss), как более устойчивая к выбросам. Если <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo separator="true">,</mo><mi>h</mi><mo separator="true">,</mo><mi>w</mi><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left(x,y,h,w\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">h</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mclose delimcenter" style="top:0em">)</span></span></span></span></span> - истинная рамка, а <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><mover accent="true"><mi>x</mi><mo stretchy="true">^</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>h</mi><mo stretchy="true">^</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>w</mi><mo stretchy="true">^</mo></mover><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left(\widehat{x},\widehat{y},\widehat{h},\widehat{w}\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6706em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span class="svg-align" style="width:calc(100% - 0.0556em);margin-left:0.0556em;top:-3.4306em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6706em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span class="svg-align" style="width:calc(100% - 0.1111em);margin-left:0.1111em;top:-3.4306em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9344em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span class="svg-align" style="top:-3.6944em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6706em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.4306em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span></span></span></span> - предсказанная, то локализующая регрессия учится предсказывать величины</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo fence="true">(</mo><mfrac><mrow><mi>x</mi><mo>−</mo><mover accent="true"><mi>x</mi><mo stretchy="true">^</mo></mover></mrow><mi>w</mi></mfrac><mo separator="true">,</mo><mfrac><mrow><mi>y</mi><mo>−</mo><mover accent="true"><mi>y</mi><mo stretchy="true">^</mo></mover></mrow><mi>h</mi></mfrac><mo separator="true">,</mo><mi>ln</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mover accent="true"><mi>w</mi><mo stretchy="true">^</mo></mover><mi>w</mi></mfrac><mo fence="true">)</mo></mrow><mo separator="true">,</mo><mi>ln</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mover accent="true"><mi>h</mi><mo stretchy="true">^</mo></mover><mi>h</mi></mfrac><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\left(\frac{x-\widehat{x}}{w},\frac{y-\widehat{y}}{h},\ln\left(\frac{\widehat{w}}{w}\right),\ln\left(\frac{\widehat{h}}{h}\right)\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3476em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6706em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">x</span></span><span class="svg-align" style="width:calc(100% - 0.0556em);margin-left:0.0556em;top:-3.4306em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3476em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6706em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span><span class="svg-align" style="width:calc(100% - 0.1111em);margin-left:0.1111em;top:-3.4306em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em"><span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3476em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em">w</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6706em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal" style="margin-right:0.02691em">w</span></span><span class="svg-align" style="width:calc(100% - 0.1667em);margin-left:0.1667em;top:-3.4306em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6114em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9344em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mathnormal">h</span></span><span class="svg-align" style="top:-3.6944em"><span class="pstrut" style="height:3em"></span><span style="height:0.24em"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="0.24em" viewBox="0 0 1062 239" preserveAspectRatio="none"><path d="M529 0h5l519 115c5 1 9 5 9 10 0 1-1 2-1 3l-4 22
c-1 5-5 9-11 9h-2L532 67 19 159h-2c-5 0-9-4-11-9l-5-22c-1-6 2-12 8-13z"></path></svg></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size4">)</span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size4">)</span></span></span></span></span></span></span>
<p>Такие целевые переменные позволяют устойчивее предсказывать координаты угла рамки для рамок разных размеров и сильнее штрафуют недостаточное выделение объекта, чем избыточное.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Faster R-CNN</div><div class="admonitionContent_BuS1"><p>В сети, предсказывающей регионы-кандидаты модели Faster R-CNN, используются точно такие же потери локализации.</p></div></div>
<p>Настройка Fast R-CNN велась для исходных изображений и их горизонтально отражённых версий, используя разный масштаб (разрешение) этих изображений, чтобы детектор учился выделять как большие, так и маленькие объекты.</p>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Повышение полноты детекций</div><div class="admonitionContent_BuS1"><p>Для повышения полноты (recall) обнаруживаемых объектов в Mask R-CNN предлагалось во время обучения и во время использования модели запускать её на изображении в различных масштабах (более крупных и более мелких).</p><p>Это замедляет настройку и построение прогнозов, зато улучшает качество детекций для слишком больших и малых объектов.</p><p>Заметим, что этот приём применим не только к Fast R-CNN, но вообще к любым моделям детекции.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="историческая-справка">Историческая справка<a class="hash-link" aria-label="Прямая ссылка на Историческая справка" title="Прямая ссылка на Историческая справка" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#историческая-справка">​</a></h2>
<p>Одним из первых нейросетевых детекторов была модель R-CNN [<a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html" target="_blank" rel="noopener noreferrer">5</a>]. Она работала очень медленно, поскольку каждый регион-кандидат отдельно и независимо обрабатывался свёрточным кодировщиком, а для того, чтобы зафиксировать выходной эмбеддинг, регион-кандидат перемасштабировался к единому размеру, что приводило к искажениям и ошибкам классификации.</p>
<p>Идея не пропускать каждый регион-кандидат через кодировщик, а пропустить через него сразу всё из ображение, а потом выделять нужные регионы-кандидаты на полученных картах признаков, была впоследствии предложена в модели SPP-net [<a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener noreferrer">6</a>]. Это существенно ускорило скорость обработки, поскольку не приводило к повторным перевычислениям одних и тех же признаков на пересекающихся рамках.</p>
<p>Также в SPP-net была впервые предложена идея кодировать признаковое описание региона-кандидата, используя пирамидальный пулинг.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="литература">Литература<a class="hash-link" aria-label="Прямая ссылка на Литература" title="Прямая ссылка на Литература" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#литература">​</a></h2>
<ol>
<li>
<p><a href="https://papers.nips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html" target="_blank" rel="noopener noreferrer">Ren, S., He, K., Girshick, R., Sun, J. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks // Advances in Neural Information Processing Systems (NIPS). – 2015. – Vol. 28. – P. 91–99. DOI: 10.5555/2969239.2969250.</a></p>
</li>
<li>
<p><a href="https://www.researchgate.net/publication/324903264_Multi-scale_object_detection_in_remote_sensing_imagery_with_convolutional_neural_networks" target="_blank" rel="noopener noreferrer">Deng Z. et al. Multi-scale object detection in remote sensing imagery with convolutional neural networks //ISPRS journal of photogrammetry and remote sensing. – 2018. – Т. 145. – С. 3-22.</a></p>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html" target="_blank" rel="noopener noreferrer">Girshick, R. Fast R-CNN // Proceedings of the IEEE International Conference on Computer Vision (ICCV). – 2015. – P. 1440–1448. DOI: 10.1109/ICCV.2015.169.</a></p>
</li>
<li>
<p><a href="http://www.huppelen.nl/publications/selectiveSearchDraft.pdf" target="_blank" rel="noopener noreferrer">Uijlings J. R. R. et al. Selective search for object recognition //International journal of computer vision. – 2013. – Т. 104. – С. 154-171.</a></p>
</li>
<li>
<p><a href="https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html" target="_blank" rel="noopener noreferrer">Girshick R. et al. Rich feature hierarchies for accurate object detection and semantic segmentation //Proceedings of the IEEE conference on computer vision and pattern recognition. – 2014. – С. 580-587.</a></p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1406.4729" target="_blank" rel="noopener noreferrer">He K. et al. Spatial pyramid pooling in deep convolutional networks for visual recognition //IEEE transactions on pattern analysis and machine intelligence. – 2015. – Т. 37. – №. 9. – С. 1904-1916.</a></p>
</li>
</ol></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Страница документа"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Neural-networks/Object-detection/CenterNet"><div class="pagination-nav__sublabel">Предыдущая страница</div><div class="pagination-nav__label">CenterNet</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Neural-networks/Object-detection/Deformable-CNN"><div class="pagination-nav__sublabel">Следующая страница</div><div class="pagination-nav__label">Деформируемые архитектуры</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#faster-r-cnn">Faster R-CNN</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#fast-r-cnn">Fast R-CNN</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#алгоритм-selective-search">Алгоритм selective search</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#обработка-регионов-кандидатов-в-fast-rcnn">Обработка регионов-кандидатов в Fast-RCNN</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#настройка-fast-r-cnn">Настройка Fast R-CNN</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#историческая-справка">Историческая справка</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/Object-detection/Two-stage-detectors#литература">Литература</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2023-24 <a href="https://victorkitov.github.io/">Виктор Китов</a>.</div></div></div></footer></div>
</body>
</html>