<!doctype html>
<html lang="ru" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Neural-networks/MLP/Activation-functions" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">Функции активации | Машинное и глубокое обучение</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://deepmachinelearning.ru/img/social-card.png"><meta data-rh="true" name="twitter:image" content="https://deepmachinelearning.ru/img/social-card.png"><meta data-rh="true" property="og:url" content="https://deepmachinelearning.ru/docs/Neural-networks/MLP/Activation-functions"><meta data-rh="true" property="og:locale" content="ru"><meta data-rh="true" name="docusaurus_locale" content="ru"><meta data-rh="true" name="docsearch:language" content="ru"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Функции активации | Машинное и глубокое обучение"><meta data-rh="true" name="description" content="Основные функции активации в нейросетях. Определения, графики, примеры использования и отличия на качественном уровне."><meta data-rh="true" property="og:description" content="Основные функции активации в нейросетях. Определения, графики, примеры использования и отличия на качественном уровне."><meta data-rh="true" name="keywords" content="активации нейронной сети,активация,activation function,линейная активация,сигмоидная активация,гиперболический тангенс,ReLU,Leaky ReLU,нейронная сеть,искусственные нейронные сети"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://deepmachinelearning.ru/docs/Neural-networks/MLP/Activation-functions"><link data-rh="true" rel="alternate" href="https://deepmachinelearning.ru/docs/Neural-networks/MLP/Activation-functions" hreflang="ru"><link data-rh="true" rel="alternate" href="https://deepmachinelearning.ru/docs/Neural-networks/MLP/Activation-functions" hreflang="x-default"><link rel="preconnect" href="https://mc.yandex.ru">
<script>!function(e,t,a,c,n,r,i){e[n]=e[n]||function(){(e[n].a=e[n].a||[]).push(arguments)},e[n].l=1*new Date,r=t.createElement(a),i=t.getElementsByTagName(a)[0],r.async=1,r.src="https://mc.yandex.ru/metrika/tag.js",i.parentNode.insertBefore(r,i)}(window,document,"script",0,"ym"),ym(98444042,"init",{defer:!0,clickmap:!0,trackLinks:!0,accurateTrackBounce:!0,webvisor:!1,ecommerce:!1,trackHash:!1})</script>
<noscript>
                            <div><img src="https://mc.yandex.ru/watch/98444042" style="position:absolute; left:-9999px;" alt=""></div>
                        </noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b8c6d6fc.css">
<script src="/assets/js/runtime~main.bce454a7.js" defer="defer"></script>
<script src="/assets/js/main.a48d3130.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Перейти к основному содержимому"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Перейти к основному содержимому</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Переключить навигационную панель" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="site logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.png" alt="site logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/docs/Machine-learning/book-title">Машинное обучение</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/Neural-networks/book-title">Глубокое обучение</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/docs/abbreviations">Обозначения</a><a class="navbar__item navbar__link" href="/license">Лицензия</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Переключение между темным и светлым режимом (сейчас используется Светлый режим)" aria-label="Переключение между темным и светлым режимом (сейчас используется Светлый режим)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Прокрутка к началу" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Neural-networks/book-title">Глубокое обучение</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Neural-networks/intro">Введение</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Tasks-of-deep-learning">Примеры задач глубокого обучения</a><button aria-label="Expand sidebar category &#x27;Примеры задач глубокого обучения&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/Neural-networks/Multilayer-perceptron">Основы нейросетевых архитектур</a><button aria-label="Collapse sidebar category &#x27;Основы нейросетевых архитектур&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/Neuron-model">Модель нейрона</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/Multilayer-perceptron">Многослойный персептрон</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Neural-networks/MLP/Activation-functions">Функции активации</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/Outputs-loss-functions">Выходы нейросети и функции потерь</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/Weights-symmetries">Симметрия в пространстве весов</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/Modeling-ability">Моделирующие способности нейросети</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/Representation-learning">Обучение представлений</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Neural-networks/MLP/HyperNet">Гиперсеть</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Training-neural-networks">Обучение нейросетей</a><button aria-label="Expand sidebar category &#x27;Обучение нейросетей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Training-simplification">Упрощение настройки</a><button aria-label="Expand sidebar category &#x27;Упрощение настройки&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Regularization">Регуляризация при настройке нейросетей</a><button aria-label="Expand sidebar category &#x27;Регуляризация при настройке нейросетей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Special-architectures">Специальные архитектуры</a><button aria-label="Expand sidebar category &#x27;Специальные архитектуры&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Convolution-for-sequences-1D">Локальная обработка последовательностей</a><button aria-label="Expand sidebar category &#x27;Локальная обработка последовательностей&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Convolution-for-images-2D">Локальная обработка изображений</a><button aria-label="Expand sidebar category &#x27;Локальная обработка изображений&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Convolutional-architectures">Основные свёрточные архитектуры</a><button aria-label="Expand sidebar category &#x27;Основные свёрточные архитектуры&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Semantic-segmentation">Семантическая сегментация</a><button aria-label="Expand sidebar category &#x27;Семантическая сегментация&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Object-detection">Детекция объектов</a><button aria-label="Expand sidebar category &#x27;Детекция объектов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Instance-segmentation">Сегментация объектов</a><button aria-label="Expand sidebar category &#x27;Сегментация объектов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Embeddings">Эмбеддинги слов и параграфов</a><button aria-label="Expand sidebar category &#x27;Эмбеддинги слов и параграфов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Recurrent-neural-nets">Рекуррентные сети</a><button aria-label="Expand sidebar category &#x27;Рекуррентные сети&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Transformer">Трансформер</a><button aria-label="Expand sidebar category &#x27;Трансформер&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" href="/docs/Neural-networks/Graph-processing">Обработка графов</a><button aria-label="Expand sidebar category &#x27;Обработка графов&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/Neural-networks/conclusion">Заключение</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Навигационная цепочка текущей страницы"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Главная страница" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/Neural-networks/Multilayer-perceptron"><span itemprop="name">Основы нейросетевых архитектур</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Функции активации</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">Содержание этой страницы</button></div><div class="theme-doc-markdown markdown"><h1>Функции активации</h1>
<p>Рассмотрим популярные функции активации <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(u)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span></span></span></span>, использующиеся в нейросетях.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="тождественная-функция-активации-identity">Тождественная фун кция активации (identity)<a class="hash-link" aria-label="Прямая ссылка на Тождественная функция активации (identity)" title="Прямая ссылка на Тождественная функция активации (identity)" href="/docs/Neural-networks/MLP/Activation-functions#тождественная-функция-активации-identity">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>u</mi></mrow><annotation encoding="application/x-tex">h(u)=u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">u</span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/identity-3635296ddde09ce162dfba73246598ed.png" width="640" height="480" class="img_ev3q"></p>
<p>Эта активация используется в выходном слое, чтобы моделировать регрессионный выход. В скрытых слоях почти не используется, т.к. суперпозиция линейных функций  приводит к линейной функции.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="сигмоидная-функция-активации-sigmoid">Сигмоидная функция активации (sigmoid)<a class="hash-link" aria-label="Прямая ссылка на Сигмоидная функция активации (sigmoid)" title="Прямая ссылка на Сигмоидная функция активации (sigmoid)" href="/docs/Neural-networks/MLP/Activation-functions#сигмоидная-функция-активации-sigmoid">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>u</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">h(u)=\sigma(u)=\frac{1}{1+e^{-u}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-0.7693em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/sigmoid-f027b17aeb990682687688cb3fcf887d.png" width="640" height="480" class="img_ev3q"></p>
<p>Принимает значения <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(u)\in(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> и используется в выходном слое нейронной сети для решения задачи бинарной классификации, предсказывая вероятность положительного класса <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>y</mi><mo>=</mo><mo>+</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(y=+1|\mathbf{x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">+</span><span class="mord">1∣</span><span class="mord mathbf">x</span><span class="mclose">)</span></span></span></span>.</p>
<p>В скрытых слоях почти не используется, поскольку за пределами интервала <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>−</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(-3,3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">3</span><span class="mclose">)</span></span></span></span> выходит на горизонтальные асимптоты -1 и +1, почти не меняясь, в результате чего её градиент близок к нулю. Поскольку нейросети оптимизируются численными методами, используя градиент, это приводит к медленной настройке сети и даже застреванию сигмоидных активаций в районе значений <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>±</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\pm 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">±</span><span class="mord">1</span></span></span></span>.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="гиперболический-тангенс-tangh">Гиперболический тангенс (tangh)<a class="hash-link" aria-label="Прямая ссылка на Гиперболический тангенс (tangh)" title="Прямая ссылка на Гиперболический тангенс (tangh)" href="/docs/Neural-networks/MLP/Activation-functions#гиперболический-тангенс-tangh">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>tangh</mtext><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><msup><mi>e</mi><mi>u</mi></msup><mo>−</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>u</mi></mrow></msup></mrow><mrow><msup><mi>e</mi><mi>u</mi></msup><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>u</mi></mrow></msup></mrow></mfrac><mo>=</mo><mn>2</mn><mi>σ</mi><mo stretchy="false">(</mo><mn>2</mn><mi>u</mi><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">h(u)=\text{tangh}(u)=\frac{e^{u}-e^{-u}}{e^{u}+e^{-u}}=2\sigma(2u)-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">tangh</span></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.2177em;vertical-align:-0.7693em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4483em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5904em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em"><span style="top:-2.989em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.03588em">σ</span><span class="mopen">(</span><span class="mord">2</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/tangh-1b4e9c94adbb6c65143cddfdfdbd62fd.png" width="640" height="480" class="img_ev3q"></p>
<p>С точностью до линейного сжатия и сдвига совпадает с сигмоидной функцией активации, но, в отличие от неё, является нечётной функцией:</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>tangh</mtext><mo stretchy="false">(</mo><mo>−</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mtext>tangh</mtext><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\text{tangh}(-u)=-\text{tangh}(u),</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">tangh</span></span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord">−</span><span class="mord text"><span class="mord">tangh</span></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mpunct">,</span></span></span></span></span>
<p>что даёт преимущество при инициализации и настройке нейросети за счёт того, что если признаки - случайные величинами, центрированные вокруг нуля, то образованные от них активации также будут центрированными вокруг нуля, а также активации от активаций и так далее по всем слоям нейросети, т.е. по ходу вычислений не будет происходит систематического смещения в ту или иную сторону.</p>
<p>Тем не менее, гиперболический тангенс используется в основном только в выходных регрессионных слоях, где есть ограничение на выход и снизу, и сверху, например, где нужно генерировать степень поворота руля <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-1,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>, чтобы оптимально объехать препятствие.</p>
<p>В скрытых слоях он практически не используется, поскольку обладает тем же недостатком, что и сигмоида: за пределами интервала <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>−</mo><mn>3</mn><mo separator="true">,</mo><mn>3</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(-3,3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">3</span><span class="mclose">)</span></span></span></span> выходит на горизонтальные асимптоты -1 и +1 и почти не изменяется, из-за чего градиент по активации становится близким к нулю, и сеть начинает слишком медленно настраиваться.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="плавная-функция-знака-softsign">Плавная функция знака (SoftSign)<a class="hash-link" aria-label="Прямая ссылка на Плавная функция знака (SoftSign)" title="Прямая ссылка на Плавная функция знака (SoftSign)" href="/docs/Neural-networks/MLP/Activation-functions#плавная-функция-знака-softsign">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mi>u</mi><mrow><mn>1</mn><mo>+</mo><mi mathvariant="normal">∣</mi><mi>u</mi><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">h(u) = \frac{u}{1+|u|}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.0436em;vertical-align:-0.936em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1076em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord">∣</span><span class="mord mathnormal">u</span><span class="mord">∣</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">u</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/soft-sign-e406d57c4f078b6b7260a756feb966bd.png" width="640" height="480" class="img_ev3q"></p>
<p>Soft-sign активация идейно повторяет tangh-активацию, но имеет характер приближения к асимптотам +1 и -1 полиномиальный, а не экспоненциальный. Т.е. на константные значения <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>±</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\pm 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">±</span><span class="mord">1</span></span></span></span> функция выходит медленнее, что улучшает сходимость при настройке сети. Также soft-sign активация вычисляется быстрее, чем tangh. Тем не менее, из-за наличия горизонтальных асимптот в скрытых слоях используется редко.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="жёсткий-гиперболический-тангенс-hard-tangh">Жёсткий гиперболический тангенс (hard tangh)<a class="hash-link" aria-label="Прямая ссылка на Жёсткий гиперболический тангенс (hard tangh)" title="Прямая ссылка на Жёсткий гипе рболический тангенс (hard tangh)" href="/docs/Neural-networks/MLP/Activation-functions#жёсткий-гиперболический-тангенс-hard-tangh">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mo>−</mo><mn>1</mn><mo separator="true">;</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>u</mi><mo separator="true">,</mo><mo>+</mo><mn>1</mn><mo stretchy="false">}</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">h(u)=\max\{-1;\min\{u,+1\}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">max</span><span class="mopen">{</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">min</span><span class="mopen">{</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">+</span><span class="mord">1</span><span class="mclose">}}</span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/hard-tangh-8ebd125cb4dd34f9c70cfbf9983ec6b8.png" width="640" height="480" class="img_ev3q"></p>
<p>Используется так же, как и обычный гиперболический тангенс, но гораздо быстрее вычисляется за счёт ещё более простых операций. Вычисление получается более точным и устойчивым, что актуально при использовании низкобитных представлений чисел (float16, int8) при построении компактных нейросетей для мобильных устройств.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="softplus">SoftPlus<a class="hash-link" aria-label="Прямая ссылка на SoftPlus" title="Прямая ссылка на SoftPlus" href="/docs/Neural-networks/MLP/Activation-functions#softplus">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>ln</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi><mi>u</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">h(u)=\ln (1+e^u)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">ln</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/SoftPlus-27c4d8c07d83f20bfbedba41b7dc44ac.png" width="640" height="480" class="img_ev3q"></p>
<p>Имеет нетривиальный градиент уже на полуоси <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>≥</mo><mo>−</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">u\ge -3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7719em;vertical-align:-0.136em"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">3</span></span></span></span>, за счёт чего используется в скрытых слоях. Также используется и в выходных слоях, где нужно предсказывать регрессионный отклик, который должен быть неотрицательным (например, когда предсказываем время до наступления некоторого события, зная, что оно ещё не наступило).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rectified-linear-unit-relu">Rectified linear unit (ReLU)<a class="hash-link" aria-label="Прямая ссылка на Rectified linear unit (ReLU)" title="Прямая ссылка на Rectified linear unit (ReLU)" href="/docs/Neural-networks/MLP/Activation-functions#rectified-linear-unit-relu">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">;</mo><mi>u</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">h(u) = \max\{0;u\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">max</span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">u</span><span class="mclose">}</span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="data:image/png;base64,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" width="640" height="480" class="img_ev3q"></p>
<p>Имеет нетривиальный градиент +1 на полуоси <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">u&gt;0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span> , за счёт чего используется как в скрытых слоях, так и в выходных слоях, где нужно предсказывать неотрицательный регрессионный отклик.</p>
<p>Идейно повторяя SoftPlus-активацию, вычисляется гораздо быстрее и устойчивее при низкобитных представлениях чисел в облегчённых нейросетевых моделях. <strong>Одна из самых популярный функций активации.</strong></p>
<p>ReLU обладает тем недостатком, что зануляет отрицательные значения, в результате чего, если нейрону приходят только отрицательные значения, то он расходует вычисления, но выдаёт тождественный ноль (dead neuron).</p>
<p>Формально, в нуле градиент этой функции активации не определён. Однако это не приводит к проблемам на практике, т.к. пр и случайной инициализации весов и случайных значениях признаков значение в точности равное нулю в общем случае не реализуется.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="leaky-rectified-linear-unit-leaky-relu">Leaky rectified linear unit (Leaky ReLU)<a class="hash-link" aria-label="Прямая ссылка на Leaky rectified linear unit (Leaky ReLU)" title="Прямая ссылка на Leaky rectified linear unit (Leaky ReLU)" href="/docs/Neural-networks/MLP/Activation-functions#leaky-rectified-linear-unit-leaky-relu">​</a></h2>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mi>α</mi><mi>u</mi><mo separator="true">;</mo><mi>u</mi><mo stretchy="false">}</mo><mo separator="true">,</mo><mtext>  </mtext><mi>α</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo><mo>−</mo><mtext>гиперпараметр.</mtext></mrow><annotation encoding="application/x-tex">h(u)=\max\{ \alpha u; u \},\; \alpha\in (0,1) - \text{гиперпараметр.}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">h</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mop">max</span><span class="mopen">{</span><span class="mord mathnormal">αu</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">u</span><span class="mclose">}</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord text"><span class="mord cyrillic_fallback">гиперпараметр</span><span class="mord">.</span></span></span></span></span></span>
<p><img decoding="async" loading="lazy" src="/assets/images/leaky-ReLU-f40569e9da813b9ddebed0e35d65d1ec.png" width="640" height="480" class="img_ev3q"></p>
<p>Обладает всеми достоинствами ReLU активации, но помимо этого имеет нетривиальный градиент <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\alpha\in(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5782em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span> и в отрицательной области, за счёт чего нейрон всегда выдаёт нетривиальные значения, а не вырождается в константу. <strong>Рекомендуется к использованию как наилучший вариант</strong>.</p>
<p>В классическом LeakyReLU <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.01</mn></mrow><annotation encoding="application/x-tex">\alpha=0.01</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0.01</span></span></span></span>, хотя можно использовать и другие значения и даже настраивать его как параметр вместе с остальными весами нейросети.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Страница документа"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Neural-networks/MLP/Multilayer-perceptron"><div class="pagination-nav__sublabel">Предыдущая страница</div><div class="pagination-nav__label">Многослойный персептрон</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Neural-networks/MLP/Outputs-loss-functions"><div class="pagination-nav__sublabel">Следующая страница</div><div class="pagination-nav__label">Выходы нейросети и функции потерь</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#тождественная-функция-активации-identity">Тождественная функция активации (identity)</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#сигмоидная-функция-активации-sigmoid">Сигмоидная функция активации (sigmoid)</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#гиперболический-тангенс-tangh">Гиперболический тангенс (tangh)</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#плавная-функция-знака-softsign">Плавная функция знака (SoftSign)</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#жёсткий-гиперболический-тангенс-hard-tangh">Жёсткий гиперболический тангенс (hard tangh)</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#softplus">SoftPlus</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#rectified-linear-unit-relu">Rectified linear unit (ReLU)</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/Neural-networks/MLP/Activation-functions#leaky-rectified-linear-unit-leaky-relu">Leaky rectified linear unit (Leaky ReLU)</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">© 2023-25 <a href="https://victorkitov.github.io/">Виктор Китов</a>.</div></div></div></footer></div>
</body>
</html>